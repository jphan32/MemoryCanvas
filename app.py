import gradio as gr
import base64
import uuid
import shutil

import os
import requests
from openai import OpenAI


client = OpenAI()

headers = {
  "Content-Type": "application/json",
  "Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}"
}


def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def draw_image(class_value, name_value, text_value, image_path, image_gallery):
    if not class_value or not name_value:
        gr.Warning("í•™ë…„ ë°˜ ë²ˆí˜¸ì™€ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", duration=5)
        return None

    if not text_value:
        gr.Warning("ì–´ë–¤ ê·¸ë¦¼ì„ ê·¸ë¦´ì§€ ì¸ê³µì§€ëŠ¥ì—ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.", duration=5)
        return None

    # Generate prompt for the drawing image generation
    if image_path:
        base64_image = encode_image(image_path)

        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"""Describe the attached image in text, translate the user's input into English, and combine them into a prompt for DALL-E to generate an image.
Print ONLY the combined prompt as a string.

Example:
```
1. Image description: **attached image**
2. User input (in English): ë°°ê²½ ê·¸ë¦¼ì— ì‚°ì„ ì¶”ê°€í•´ì¤˜.
3. Combined prompt: A red lighthouse standing against the backdrop of the sea under a blue sky. Please add mountains in the background.
```
```
1. Image description: **attached image**
2. User input (in English): í•˜ëŠ˜ì„ ë‚˜ëŠ” ë¯¸ë˜í˜• ë¹„í–‰ ìë™ì°¨ë¥¼ ê·¸ë ¤ì¤˜.
3. Combined prompt: A busy city street at night with bright neon signs and a crowd of people walking. Please add a futuristic flying car in the sky.
```
===

User input:
1. Image description: **attached image**
2. User input (in English): {text_value}.
3. Combined prompt: """
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 2000
        }

        json = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload).json()
        # print(json["choices"][0]["message"]["content"])
        text_value = json["choices"][0]["message"]["content"]

    response = client.images.generate(
        model="dall-e-3",
        prompt=text_value,
        size="1024x1024",
        quality="hd",
        n=1,
    )

    image_url = response.data[0].url
    processed_image = gr.Image(image_url, interactive=False)

    # Update image gallery
    if not image_gallery:
        image_gallery = [image_url]
    else:
        image_gallery.append(image_url)

    return processed_image, image_gallery


def save_image(image_gallery, class_value, name_value):
    if not image_gallery or not class_value or not name_value:
        return

    print(image_gallery)
    for img in image_gallery:
        unique_filename = f"./work/{class_value}_{name_value}_{uuid.uuid4()}.png"
        print(img[0], unique_filename)
        shutil.copy2(img[0], unique_filename)
    """
    image_data = requests.get(image_gallery).content
    unique_filename = f"{class_value}_{name_value}_{uuid.uuid4()}.png"
    with open(unique_filename, "wb") as f:
        f.write(image_data)
    print(f"Image saved as {unique_filename}")
    """


with gr.Blocks() as demo:
    gr.Markdown("# âœ¨ ì¸ê³µì§€ëŠ¥ê³¼ í•¨ê»˜ ê·¸ë¦¬ëŠ” ìš°ë¦¬ ë§ˆì„ ì´ì•¼ê¸° ğŸï¸")

    gr.Markdown("## ëˆ„ê°€ ê·¸ë¦´ê¹Œìš”? ğŸ‘©â€ğŸ¨")
    with gr.Row():
        with gr.Column():
            class_input = gr.Textbox(label="í•™ë…„ ë°˜ ë²ˆí˜¸", lines=1)
        with gr.Column():
            name_input = gr.Textbox(label="ì´ë¦„", lines=1)

    gr.Markdown("## ì–´ë–¤ ê·¸ë¦¼ì„ ê·¸ë¦´ê¹Œìš”? ğŸ¨")
    with gr.Row():
        with gr.Column():
            text_input = gr.Textbox(label="ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", lines=10)
        with gr.Column():
            image_input = gr.Image(label="ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.", type="filepath")
    with gr.Row():
        draw_button = gr.Button("ê·¸ë¦¼ ê·¸ë¦¬ê¸°")

    gr.Markdown("---")
    gr.Markdown("## ê·¸ë¦¼ ê²°ê³¼ë¬¼ ğŸ–¼ï¸")
    with gr.Row():
        processed_image = gr.Image(label="ê·¸ë¦¼ ê²°ê³¼ë¬¼", interactive=False)

    with gr.Row():
        image_gallery = gr.Gallery(label="ì§€ê¸ˆê¹Œì§€ ê·¸ë¦° ê·¸ë¦¼ë“¤", interactive=False)

    save_button = gr.Button("ì„ íƒí•œ ì´ë¯¸ì§€ ì €ì¥í•˜ê¸°")

    # Event Handlers
    draw_button.click(draw_image,
                      inputs=[class_input, name_input, text_input, image_input, image_gallery],
                      outputs=[processed_image, image_gallery])
    save_button.click(save_image, inputs=[image_gallery, class_input, name_input], outputs=[])

if __name__ == "__main__":
    demo.queue().launch(share=True, debug=True)
