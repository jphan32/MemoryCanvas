import gradio as gr
import base64
import uuid
import shutil

import os
import requests
from openai import OpenAI

client = OpenAI()

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}"
}


def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def draw_image(class_value, name_value, text_value, image_path, images):
    if not class_value or not name_value:
        gr.Warning("í•™ë…„ ë°˜ ë²ˆí˜¸ì™€ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", duration=5)
        return None, images

    if not text_value:
        gr.Warning("ì–´ë–¤ ê·¸ë¦¼ì„ ê·¸ë¦´ì§€ ì¸ê³µì§€ëŠ¥ì—ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.", duration=5)
        return None, images

    # Generate prompt for the drawing image generation
    if image_path:
        base64_image = encode_image(image_path)

        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"""Describe the attached image in text, translate the user's input into English, and combine them into a prompt for DALL-E to generate an image.
Print ONLY the combined prompt as a string.

Example:
```
1. Image description: **attached image**
2. User input (in English): ë°°ê²½ ê·¸ë¦¼ì— ì‚°ì„ ì¶”ê°€í•´ì¤˜.
3. Combined prompt: A red lighthouse standing against the backdrop of the sea under a blue sky. Please add mountains in the background.
```
```
1. Image description: **attached image**
2. User input (in English): í•˜ëŠ˜ì„ ë‚˜ëŠ” ë¯¸ë˜í˜• ë¹„í–‰ ìë™ì°¨ë¥¼ ê·¸ë ¤ì¤˜.
3. Combined prompt: A busy city street at night with bright neon signs and a crowd of people walking. Please add a futuristic flying car in the sky.
```
===

User input:
1. Image description: **attached image**
2. User input (in English): {text_value}.
3. Combined prompt: """
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 2000
        }

        json = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload).json()
        # print(json["choices"][0]["message"]["content"])
        text_value = json["choices"][0]["message"]["content"]

    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=text_value,
            size="1024x1024",
            quality="hd",
            n=1,
        )
    except Exception as e:
        gr.Warning("ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•œ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ë³´ì„¸ìš”.", duration=5)
        return None, images

    image_url = response.data[0].url
    drawing_image = gr.Image(image_url, interactive=False)

    # Update image gallery
    if not images:
        images = [image_url]
    else:
        images.append(image_url)

    return drawing_image, images


def get_select_index(evt: gr.SelectData):
    return evt.index


def save_image(images, selected_index, class_value, name_value):
    if not images or not class_value or not name_value:
        gr.Error("ì €ì¥í•  ì´ë¯¸ì§€ê°€ ì—†ê±°ë‚˜ ì´ë¦„ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", duration=5)
        return

    if selected_index == -1:
        gr.Warning("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", duration=5)
        return

    print(images, selected_index)
    for img in images:
        unique_filename = f"./work/{class_value}_{name_value}_{uuid.uuid4()}.png"
        print(img[0], unique_filename)
        shutil.copy2(img[0], unique_filename)

    if selected_index is not None:
        shutil.copy2(images[selected_index][0], f"./work/{class_value}_{name_value}_Selected.png")

    gr.Info("ì„ íƒí•œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.", duration=5)


with gr.Blocks() as demo:
    gr.Markdown("# âœ¨ ì¸ê³µì§€ëŠ¥ê³¼ í•¨ê»˜ ê·¸ë¦¬ëŠ” ìš°ë¦¬ ë§ˆì„ ì´ì•¼ê¸° ğŸï¸")

    gr.Markdown("## ëˆ„ê°€ ê·¸ë¦´ê¹Œìš”? ğŸ‘©â€ğŸ¨")
    with gr.Row():
        with gr.Column():
            class_input = gr.Textbox(label="í•™ë…„ ë°˜ ë²ˆí˜¸", lines=1, placeholder="ì˜ˆ) 6101")
        with gr.Column():
            name_input = gr.Textbox(label="ì´ë¦„", lines=1)

    gr.Markdown("## ì–´ë–¤ ê·¸ë¦¼ì„ ê·¸ë¦´ê¹Œìš”? ğŸ¨")
    with gr.Row():
        with gr.Column():
            text_input = gr.Textbox(label="ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•  ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", lines=10,
                                    placeholder="ì˜ˆ) ë§Œí™” ìºë¦­í„° ê³ ì–‘ì´ë¥¼ ìˆ˜ì±„í™” ëŠë‚Œìœ¼ë¡œ ê·¸ë ¤ì¤˜.")
        with gr.Column():
            image_input = gr.Image(label="ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.", type="filepath")
    with gr.Row():
        draw_button = gr.Button("ê·¸ë¦¼ ê·¸ë¦¬ê¸°")

    gr.Markdown("---")
    gr.Markdown("## ê·¸ë¦¼ ê²°ê³¼ë¬¼ ğŸ–¼ï¸")
    with gr.Row():
        processed_image = gr.Image(label="ê·¸ë¦¼ ê²°ê³¼ë¬¼", interactive=False)

    with gr.Row():
        image_gallery = gr.Gallery(label="ì§€ê¸ˆê¹Œì§€ ê·¸ë¦° ê·¸ë¦¼ë“¤", columns=8, interactive=False)
        selected = gr.Number(value=-1, show_label=False, visible=False)

    save_button = gr.Button("ì„ íƒí•œ ì´ë¯¸ì§€ ì €ì¥í•˜ê¸°")

    # Event Handlers
    draw_button.click(draw_image,
                      inputs=[class_input, name_input, text_input, image_input, image_gallery],
                      outputs=[processed_image, image_gallery])
    image_gallery.select(get_select_index, None, selected)
    save_button.click(save_image, inputs=[image_gallery, selected, class_input, name_input], outputs=[])

if __name__ == "__main__":
    demo.queue().launch(share=False, debug=True)
